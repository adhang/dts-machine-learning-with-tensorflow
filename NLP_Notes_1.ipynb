{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Notes - NLP 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNU8sKMSPCFXlmC9nvTqs+/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adhang/dts-machine-learning-with-tensorflow/blob/main/NLP_Notes_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notes - Natural Language Processing 1\n",
        "\n",
        "Author: Adhang Muntaha Muhammad\n",
        "\n",
        "[![LinkedIn](https://img.shields.io/badge/linkedin-0077B5?style=for-the-badge&logo=linkedin&logoColor=white&link=https://www.linkedin.com/in/adhangmuntaha/)](https://www.linkedin.com/in/adhangmuntaha/)\n",
        "[![GitHub](https://img.shields.io/badge/github-121011?style=for-the-badge&logo=github&logoColor=white&link=https://github.com/adhang)](https://github.com/adhang)\n",
        "[![Kaggle](https://img.shields.io/badge/kaggle-20BEFF?style=for-the-badge&logo=kaggle&logoColor=white&link=https://www.kaggle.com/adhang)](https://www.kaggle.com/adhang)\n",
        "[![Tableau](https://img.shields.io/badge/tableau-E97627?style=for-the-badge&logo=tableau&logoColor=white&link=https://public.tableau.com/app/profile/adhang)](https://public.tableau.com/app/profile/adhang)\n",
        "___"
      ],
      "metadata": {
        "id": "NQXNa9kxRFAj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "7K052ZF9Ybdo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "CkE6v-eSMvgV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizer"
      ],
      "metadata": {
        "id": "1vWi-l2MM_Ba"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word Index"
      ],
      "metadata": {
        "id": "SO8F6l6rO0m8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = ['I love my cat',\n",
        "             'I love my dog']\n",
        "\n",
        "tokenizer = Tokenizer(num_words=100)\n",
        "# num_words = num of vocab that we allow\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print(word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKFirmL-NCXw",
        "outputId": "3f2ceb43-2a75-49c6-fa5c-3a9181a28699"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'i': 1, 'love': 2, 'my': 3, 'cat': 4, 'dog': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = ['I love my cat',\n",
        "             'I love my dog']\n",
        "\n",
        "tokenizer = Tokenizer(num_words=3)\n",
        "# num_words = num of vocab that we allow\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print(word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJepCTU5NaVv",
        "outputId": "ff920d9c-1803-4936-b349-a2ea53e40364"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'i': 1, 'love': 2, 'my': 3, 'cat': 4, 'dog': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "But, the `word_index` will remain the same even if we change the `num_words` limit"
      ],
      "metadata": {
        "id": "OH4rht5wOhiB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sequences"
      ],
      "metadata": {
        "id": "DhLMKE5nO2d5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Num Words Effect"
      ],
      "metadata": {
        "id": "9s0ClzLkPguI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = ['I love my cat',\n",
        "             'I love my dog']\n",
        "\n",
        "tokenizer = Tokenizer(num_words=100)\n",
        "# num_words = num of vocab that we allow\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltk6XYtmO3qS",
        "outputId": "8d1d549f-b479-4fe2-d041-d65b42b7165b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 2, 3, 4], [1, 2, 3, 5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = ['I love my cat',\n",
        "             'I love my dog']\n",
        "\n",
        "tokenizer = Tokenizer(num_words=3)\n",
        "# num_words = num of vocab that we allow\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgnwJWNKPAmN",
        "outputId": "d692da05-efac-4149-b75a-c4812cc6acb5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 2], [1, 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "See? The sequences will be trimmed if the `num_words` is less than the number of vocabs in our sentence.\n",
        "<br><br>\n",
        "The higher the `num_words`, the higher the accuracy, but it will take longer in the training process. Or it can cause an overfitting."
      ],
      "metadata": {
        "id": "7jeUptTuPCmm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### New Vocabs"
      ],
      "metadata": {
        "id": "J3HSJft2Pjru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = ['I love my cat',\n",
        "             'I love my dog']\n",
        "\n",
        "tokenizer = Tokenizer(num_words=100)\n",
        "# num_words = num of vocab that we allow\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJngrOrSPWlX",
        "outputId": "e7d3a0b4-502a-4dfd-d890-3edcadca282d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 2, 3, 4], [1, 2, 3, 5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_2 = ['You hate your cat',\n",
        "               'You hate your dog']\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(sentences_2)\n",
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OxxekwHPXjE",
        "outputId": "c41f2460-5419-4256-ae51-db0955581b7e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4], [5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Out of Vocabulary (OOV)\n",
        "\n",
        "New vocabs will be labeled with OOV"
      ],
      "metadata": {
        "id": "QelCTaINSYix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = ['I love my cat',\n",
        "             'I love my dog']\n",
        "\n",
        "tokenizer = Tokenizer(num_words=100, oov_token='<DOV>')\n",
        "# num_words = num of vocab that we allow\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print(word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLaEjC5GPeTV",
        "outputId": "da9c25e6-b554-4313-9fcd-64b753d144dc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<DOV>': 1, 'i': 2, 'love': 3, 'my': 4, 'cat': 5, 'dog': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OOV's index is always `1`"
      ],
      "metadata": {
        "id": "WA_9pE8PTK6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_2 = ['You hate your cat',\n",
        "               'You hate your dog']\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(sentences_2)\n",
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVfwfwmISr3j",
        "outputId": "728f2b65-feb3-45f7-fd1b-52909bf0dadf"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 1, 1, 5], [1, 1, 1, 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "New vocabs will be labeled with index `1` (OOV)"
      ],
      "metadata": {
        "id": "r8wHqOWeTFjY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Padding and Truncating\n",
        "\n",
        "To make sure that our 'input shape' will be the same. "
      ],
      "metadata": {
        "id": "HhZiDVw9U76H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Padding"
      ],
      "metadata": {
        "id": "2Zw4cwu7VnaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = ['I love my cat',\n",
        "             'I love my dog',\n",
        "             'I love my cat cat cat']\n",
        "\n",
        "tokenizer = Tokenizer(num_words=100, oov_token='<DOV>')\n",
        "# num_words = num of vocab that we allow\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Z_P7I8qVO8m",
        "outputId": "1e3d322f-4786-4421-a4f3-054777a8b74d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3, 4, 5, 2], [3, 4, 5, 6], [3, 4, 5, 2, 2, 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded = pad_sequences(sequences)\n",
        "print(padded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUd0IL0UVaQi",
        "outputId": "85e97e86-754c-4f2a-b1e4-808206a259e9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 3 4 5 2]\n",
            " [0 0 3 4 5 6]\n",
            " [3 4 5 2 2 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Post Padding"
      ],
      "metadata": {
        "id": "N7eJo3PEVqg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "padded = pad_sequences(sequences, padding='post')\n",
        "print(padded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smF5k14PVfkW",
        "outputId": "96814e25-9db7-42a6-b684-3d49bcb188b7"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3 4 5 2 0 0]\n",
            " [3 4 5 6 0 0]\n",
            " [3 4 5 2 2 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Truncating"
      ],
      "metadata": {
        "id": "efboCN9iV0jj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "truncated = pad_sequences(sequences, maxlen=5)\n",
        "print(truncated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ust3EJcsVvSu",
        "outputId": "08fcc8e5-6565-4a22-a79c-6261a61718b9"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 3 4 5 2]\n",
            " [0 3 4 5 6]\n",
            " [4 5 2 2 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Post Truncating"
      ],
      "metadata": {
        "id": "KMPCyuKUWIHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "truncated = pad_sequences(sequences, maxlen=5, truncating='post')\n",
        "print(truncated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1t3-mLPV6vl",
        "outputId": "31b3aa47-9369-47f0-d0b5-a522bb08a197"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 3 4 5 2]\n",
            " [0 3 4 5 6]\n",
            " [3 4 5 2 2]]\n"
          ]
        }
      ]
    }
  ]
}